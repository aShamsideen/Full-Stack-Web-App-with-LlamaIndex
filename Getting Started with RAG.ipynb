{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8978f3cb-e486-48d5-8d29-2a01747e6d15",
   "metadata": {},
   "source": [
    "#### Import required dependencies from npm and load the API key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1120b0a6-acce-408c-b298-f357742fd795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import * as mod from \"https://deno.land/std@0.213.0/dotenv/mod.ts\";\n",
    "const keys = await mod.load({export:true}) // read API key from .env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df24ee68-4d6f-437b-b526-2f5a29d1b9dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import { \n",
    "    Document, \n",
    "    VectorStoreIndex, \n",
    "    SimpleDirectoryReader \n",
    "} from \"npm:llamaindex@0.1.8\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152d9e78-1bf6-4bb4-b63a-e136255c0edf",
   "metadata": {},
   "source": [
    "#### Load our data from a local directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "183d8871-dd64-4369-9f36-a36606592439",
   "metadata": {},
   "outputs": [],
   "source": [
    "const documents = await new SimpleDirectoryReader()\n",
    "    .loadData({directoryPath: \"./data\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f955159-f287-479d-ac11-64b7cad50655",
   "metadata": {},
   "source": [
    "#### Initialize an Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "791c9ea4-ce86-444e-b284-78d791116cc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "const index = await VectorStoreIndex.fromDocuments(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1bc8733-b961-4491-8c89-16bef29ad71a",
   "metadata": {},
   "source": [
    "#### Create a query engine \n",
    "\n",
    "This convenience function combines several components:\n",
    "- Retriever\n",
    "- Postprocessing\n",
    "- Synthesizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "698dc9d2-e657-41fb-97a6-5c14326dac62",
   "metadata": {},
   "outputs": [],
   "source": [
    "const queryEngine = index.asQueryEngine()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9376eb85-410e-4a21-8e97-b9b409822d82",
   "metadata": {},
   "source": [
    "#### Let's ask a question!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f50eec9-1067-47e1-b4ad-661b62646b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "const response = await queryEngine.query({\n",
    "    query: \"What did the author do in college?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56690d9d-f890-4cee-84a6-1fd63484ee81",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.log(response.toString())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb6f3538-37a1-4981-b220-cc4420b10dab",
   "metadata": {},
   "source": [
    "#### But what just happened? let's break it down!\n",
    "\n",
    "You need an:\n",
    "- LLM to answer questions\n",
    "- embedding model to encode them"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff3a829b-b3d9-44cb-b68a-57cbd201af9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import * as llamaIndex from \"npm:llamaindex@0.1.8\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742a8ae1-4bf1-40bf-8f83-205d8c2121e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "let customLLM = new llamaIndex.OpenAI()\n",
    "let customEmbedding = new llamaIndex.OpenAIEmbedding()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3bfad58-3265-475f-8568-9f8a40c6c033",
   "metadata": {},
   "source": [
    " Let's put the LLM and the embedding model into a `ServiceContext` object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50cc9c74-1589-4760-98f7-241d58629733",
   "metadata": {},
   "outputs": [],
   "source": [
    "let customServiceContext = new llamaIndex.serviceContextFromDefaults({\n",
    "    llm: customLLM,\n",
    "    embedModel: customEmbedding\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d594241e-2b83-4d72-b4f6-cba171a1032a",
   "metadata": {},
   "source": [
    "#### Let's make our own prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36a22a1c-46c8-45ed-957d-7d04f1ca4f9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "let customQaPrompt = function({context = \"\", query = \"\"}) {\n",
    "    return `Context information is below.\n",
    "        ---------------------\n",
    "        ${context}\n",
    "        ---------------------\n",
    "        Given the context information, answer the query.\n",
    "        Include a random fact about whales in your answer.\\\n",
    "        The whale fact can come from your training data.\n",
    "        Query: ${query}\n",
    "        Answer:`\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7431bdcb-9be3-442c-a136-2e705b5c0416",
   "metadata": {},
   "source": [
    "You need a `ResponseBuilder` that uses our prompt and our service context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a657182b-7895-4ee4-8c0a-dd2ea2d0d099",
   "metadata": {},
   "outputs": [],
   "source": [
    "let customResponseBuilder = new llamaIndex.SimpleResponseBuilder(\n",
    "    customServiceContext,\n",
    "    customQaPrompt\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91456ffb-29d4-4561-b3ef-bec0dbc271b7",
   "metadata": {},
   "source": [
    "The `responseBuilder` goes to a `synthesizer`, which also needs a service context."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "021920df-3744-4b22-9a72-4fda57112032",
   "metadata": {},
   "outputs": [],
   "source": [
    "let customSynthesizer = new llamaIndex.ResponseSynthesizer({\n",
    "    responseBuilder: customResponseBuilder,\n",
    "    serviceContext: customServiceContext\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e8406e4-cd0d-4d2f-92cf-d1cf2352e867",
   "metadata": {},
   "source": [
    "You also need a `retriever`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97dd30a-80c6-416a-8d62-61c8ab88416c",
   "metadata": {},
   "outputs": [],
   "source": [
    "let customRetriever = new llamaIndex.VectorIndexRetriever({\n",
    "    index\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c2ee00c-25dc-41dd-92b7-a86600cb4330",
   "metadata": {},
   "source": [
    "The `synthesizer` and the `retriever` go to our query engine:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5758598-698d-4870-8eec-f573546ac8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "let customQueryEngine = new llamaIndex.RetrieverQueryEngine(\n",
    "    customRetriever,\n",
    "    customSynthesizer\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0f34e43-c26e-4fc1-bb6f-8a42ff33efeb",
   "metadata": {},
   "source": [
    "#### Let's check the response!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbca91c-311d-49e5-9871-cb78d6c9c210",
   "metadata": {},
   "outputs": [],
   "source": [
    "let response2 = await customQueryEngine.query({\n",
    "    query: \"What does the author think of college?\"\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5272a50f-9e06-42f1-9f69-01313972edce",
   "metadata": {},
   "outputs": [],
   "source": [
    "console.log(response2.toString())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
